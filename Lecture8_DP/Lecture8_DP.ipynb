{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Lecture 8 - Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2020-01-29 10:58:51.293704\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import funapprox_cme as fa\n",
    "\n",
    "# from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Lecture\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Infinite-Horizon Dynamic Optimization in Discrete Time](#theory)\n",
    "- [The Bellman Equation](#bellman)\n",
    "- [Value Function Iteration](#vfi)\n",
    "- [Numerical Implementation](#ngm)\n",
    "- [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Dynamic Programming is a very important tool in many areas in Economics, in particular (but not only) for solving intertemporal optimization problems. \n",
    "\n",
    "While I will introduce Dynamic Programming in the context of Macroeconomics - that is, solving variants of the neoclassical growth model - the general idea can be applied to other applications as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, in IO, dynamic programming is an important tool for structural estimation. A common application is the estimation of dynamic discrete choice models, e.g. the classical \"bus engine replacement problem\" (Rust 1987).\n",
    "\n",
    "The following is based on the exposition in Daron Acemoglu's *Modern Economic Growth*, chapter 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'theory'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Infinite-Horizon Dynamic Optimization in Discrete Time\n",
    "\n",
    "A canonical *discrete-time* *infinite-horizon* dynamic optimization problem can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{x_t, y_{t}\\right\\}_{t = 0}^{\\infty} }\\sum^\\infty_{t = 0} \\beta^t \\tilde{U}(t, x_t, y_t) \n",
    "\\end{equation}\n",
    "\n",
    "subject to\n",
    "\n",
    "\\begin{equation}\n",
    "   y_t \\in \\tilde{G}(t, x_t), \\quad \\forall t \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    x_{t + 1} = \\tilde{F}(t, x_t, y_t), \\quad \\forall t \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "and $x_0$ given.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note the following:\n",
    "\n",
    "- $x_t \\in X \\subset \\mathbb{R}^M$ is referred to as a (vector of) *state variable(s)* in period $t$.\n",
    "\n",
    "- $y_t \\in Y \\subset \\mathbb{R}^N$ denotes the (vector of) *control variable(s)* in period $t$. It can be chosen from an $N$-dimensional set $\\tilde{G}(t, x_t) \\subset Y$ which is given by a *correspondence* $\\tilde{G}$ which depends on time and the value of the state variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The function $\\tilde{F}$ specifies the evolution of the state variables over time; that is, $\\tilde{F}$ gives next period's state variables as a function of the current state vector and control vector. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $\\tilde{U}$ denotes the *instantaneous payoff* as a function of the current state and control variables, as well as time. The *objective function* is given by \n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum^\\infty_{t = 0} \\beta^t \\tilde{U}(t, x_t, y_t) \n",
    "\\end{equation}\n",
    "\n",
    "where we have already imposed the condition that the objective is a *discounted* sum of instantaneous payoffs, with $\\beta$ denoting the discount factor.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stationarity\n",
    "\n",
    "In the formulation of the problem above, the functions $\\tilde{U}$, $\\tilde{F}$, and $\\tilde{G}$ all have time $t$ as an explicit argument. If this is not the case, i.e. if we have functions $U$, $F$, and $G$ that do not *explicitly* depend on time, we have a stationary dynamic optimization problem:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{x_t, y_{t}\\right\\}_{t = 0}^{\\infty} } \\sum^\\infty_{t = 0} \\beta^t U(x_t, y_t) \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... subject to\n",
    "\n",
    "\\begin{equation}\n",
    "   y_t \\in G(x_t), \\quad \\forall t \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    x_{t + 1} = F(x_t, y_t), \\quad \\forall t \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "and $x_0$ given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example: NGM\n",
    "\n",
    "As a concrete example, we can map the abstract stationary problem above to the familiar neoclassical growth model that we have already seen multiple times. As a reminder, here is a concise description of the model: \n",
    "\n",
    "- Utility function:\n",
    "\n",
    "\\begin{equation}\n",
    "    u(c, h) = \\frac{c^{1-\\nu}}{1-\\nu} - B \\frac{h^{1+\\eta}}{1+\\eta}\n",
    "\\end{equation}\n",
    "\n",
    "with $c$ denoting consumption and $h$ labor supply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Production function:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(k_t, h_t) = A k_t^\\alpha h_t^{1-\\alpha}\n",
    "\\end{equation}\n",
    "\n",
    "with $k$ denoting the capital stock, and $A$ the productivity level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Resource Constraint:\n",
    "\n",
    "\\begin{equation}\n",
    "    k_{t+1} + c_t = f(k_t, h_t) + (1 - \\delta) k_t = A k_t^\\alpha h_t^{1-\\alpha} + (1 - \\delta) k_t\n",
    "\\end{equation}\n",
    "\n",
    "- Planner's Problem:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{c_t, k_{t+1}, h_t\\right\\}_{t = 0}^{\\infty} } \\sum^\\infty_{t = 0} \\beta^t u(c_t, h_t) \n",
    "\\end{equation}\n",
    "s.t. the resource constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using the constraint to substitute for $c_t$, the problem can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{k_t, k_{t+1}, h_t\\right\\}} \\sum^\\infty_{t = 0} \\beta^t u(f(k_t, h_t) + (1 - \\delta) k_t - k_{t+1}, h_t) \n",
    "\\end{equation}\n",
    "\n",
    "with $k_0$ given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mapping this problem to the general formulation above, we see the following:\n",
    "\n",
    "- There is one state variable, $x_t = k_t$.\n",
    "\n",
    "- The vector of choice variables is given by $y_t = (k_{t + 1}, h_t)$.\n",
    "\n",
    "- Instantaneous payoff is given by the per-period utility function $U\\big(k_t, (k_{t + 1}, h_t)\\big)  = u(f(k_t, h_t) + (1 - \\delta) k_t - k_{t+1}, h_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The function $F$ is essentially an identity function $x_{t + 1} = k_{t + 1} = F\\big(k_t, (k_{t + 1}, h_t)\\big) = k_{t + 1}$. \n",
    "\n",
    "- What is the choice set for the control variables? For $h_t$, there is no constraint other than that it cannot be negative, and hence $h_t \\in [0, \\infty)$. For $k_{t+1}$, we also have $k_{t+1} \\ge 0$. In addition, it is bounded above by $f(k_t, h_t) + (1 - \\delta)k_t$, since otherwise consumption would be negative. Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "    k_{t+1} \\in [0, f(k_t, h_t) + (1 - \\delta) k_t)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that this problem is stationary since the per-period utility function and the production function do not depend directly on time (of course, their arguments do depend on time $t$). \n",
    "\n",
    "This would not be the case if the productivity level $A$ in the production function would change with time rather than being constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If $A_t$ were to grow with a constant rate $g$, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "    A_t = (1 + g) A_{t-1} = (1 + g)^t A_0,\n",
    "\\end{equation}\n",
    "\n",
    "we could make the model stationary by transforming the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Sequential Problem\n",
    "\n",
    "Let's recap the canonical stationary problem:\n",
    "\n",
    "<a id = 'Seq'></a>\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{x_t, y_{t}\\right\\}_{t = 0}^{\\infty} } \\sum^\\infty_{t = 0} \\beta^t U(x_t, y_t) \\tag{Seq}\n",
    "\\end{equation}\n",
    "s.t.\n",
    "\\begin{equation}\n",
    "    y_t \\in G(x_t), \\quad x_{t + 1} = F(x_t, y_t), \\quad \\forall t \\ge 0, \\quad \\text{and}\\ x_0\\ \\text{given}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To solve this problem, we are looking for the sequences $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$ that attain the maximal value of the objective. We refer to these *infinite* sequences as a solution to the intertemporal optimization problem or an *optimal plan*. \n",
    "\n",
    "Our objective when solving any intertemporal optimization problem is usually to characterize this optimal plan (in practice, up to some finite period $T$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that we have solved such a *sequential* or *sequence* problem previously in the lecture on numerical optimization, in the context of the NGM. \n",
    "\n",
    "We have made an optimization algorithm (BFGS) choose a sequence (i.e. a vector) of values for capital and labor up to period $T$ (and then made use of the fact that the problem converged to steady state).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Value Function\n",
    "\n",
    "For the generic stationary problem above, let's define the *value function* \n",
    "\n",
    "\\begin{equation}\n",
    "    V^*: X \\rightarrow \\mathbb{R}\n",
    "\\end{equation}\n",
    "\n",
    "as highest possible value (i.e. the maximum) that the objective function can reach, given the initial $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "    V^*(x_0) = \\max_{\\left\\{x_t, y_{t}\\right\\}} \\sum^\\infty_{t = 0} \\beta^t U(x_t, y_t)\\quad \\text{s.t.}\\quad y_t \\in G(x_t), \\quad x_{t + 1} = F(x_t, y_t), \\quad \\forall t \\ge 0\n",
    "\\end{equation}\n",
    "\n",
    "With the optimal plan $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$, we can also write the value function as \n",
    "\n",
    "\\begin{equation}\n",
    "    V^*(x_0)  = \\sum^\\infty_{t = 0} \\beta^t U(x^*_t, y^*_t) \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'bellman'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Bellman Equation \n",
    "\n",
    "The Bellman equation is at the center of dynamic programming. It can be written in the following way:\n",
    "\n",
    "<a id = 'BE'></a>\n",
    "\\begin{equation}\n",
    "    V(x)  =  \\max_{ y \\in G(x) } \\left\\{  U(x, y) + \\beta V(x^+) \\right\\}, \\quad \\forall x \\in X \\tag{BE}\n",
    "\\end{equation}\n",
    "\n",
    "s.t. $x^+ = F(x, y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before looking at why this is useful, a few features are worth noting:\n",
    "\n",
    "- The Bellman equation is a *functional equation*: instead of finding a scalar or vector that satisfies it, we will solve it by finding an *ex-ante unknown value function $V$* which appears on both the left- and the right-hand side. This is also why the Bellman equation is called a *recursive formulation* of the intertemporal optimization problem. \n",
    "\n",
    "    Moreover, note that $V$ is ex-ante different from $V^*$, which is a particular, known value function (rather than an unknown one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Related to this, note that this functional equation must be satisfied for *all* state variables $x$ that are admissible (i.e. lie in the set $X$) \n",
    "\n",
    "- In a stationary problem, since the instantaneous payoff function does not depend on time, the choice on the right-hand side is not time dependent either. That's why we have omitted time subscripts here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- On the right-hand side, we choose the *policy* $y$ only for one period, which is a scalar or vector depending on the dimension of the control vector, given this period's state $x$. \n",
    "\n",
    "    In other words, the problem on the RHS asks what actions $y$ one should take today, given the current situation/state $x$, in order to maximize the sum of *current payoff* and *continuation value*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last point encapsulates the basic idea of dynamic programming: an optimal policy must be such that it is optimal both today - i.e., it maximizes the current return - and along the *continuation path*. The highest possible value attained by this policy is given by the value function $V$.\n",
    "\n",
    "Along this path, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision ($x^+$), and hence the continuation value is given by the same value function $V$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why is the Bellman equation useful for solving an intertemporal optimization problem? There are essentially three parts to answering this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, and most importantly, it can be shown that the recursive formulation [(BE)](#BE) above is equivalent to the sequential problem [(Seq)](#Seq), in the sense that any (feasible) optimal plan $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$ that solves the sequential problem also satisfies the Bellman equation.\n",
    "\n",
    "\\begin{equation}\n",
    "   V(x^*_t) = U(x^*_t, y^*_t) + \\beta V\\big(F(x^*_{t}, y^*_t)\\big)\\quad \\forall t \n",
    "\\end{equation}\n",
    "\n",
    "for $V = V^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hence, any solution to the sequential problem is also a solution to the recursive formulation of the problem.\n",
    "\n",
    "Note that this result follows from two theorem, the *Principle of Optimality* and the *Theorem of Equivalence*. They are outlined in the appendix, together with some heuristic arguments why this result holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Second, if we know the functional form of the value function $V$, we can easily find an optimal plan $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$ by repeatedly solving the low-dimensional problem on the right-hand side of the Bellman equation (rather than the infinite-dimensional sequential problem!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, since we have just established that any optimal plan satisfies the Bellman equation, we can use its right-hand side to solve for the optimal $(x^*_{1}, y^*_0)$ given some initial state $x_{0}$. \n",
    "\n",
    "Then, we can use $x^*_{1}$ as the initial state and solve for $(x^*_{2}, y^*_1)$ and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{align}\n",
    "            &\\max_{ y \\in G(x_0) }  U(x_0, y) + \\beta V(F(x_0, y))\\quad \\rightarrow\\quad (x_1^*, y_0^*) \\\\\n",
    "   \\quad\\rightarrow\\quad &\\max_{ y \\in G(x_1^*) }  U(x_1^*, y) + \\beta V(F(x_1^*, y))\\quad \\rightarrow\\quad (x_2^*, y_1^*) \\\\\n",
    "   \\quad\\rightarrow\\quad &\\max_{ y \\in G(x_2^*) }  U(x_2^*, y) + \\beta V(F(x_2^*, y))\\quad \\rightarrow\\quad (x_3^*, y_2^*) \\\\\n",
    "   \\quad\\rightarrow\\quad &... \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, by solving the RHS of the Bellman equation repeatedly and updating the state vector for every period, we can *generate* the sequences $\\{x^*_t, y^*_t\\}_{t = 0}^T$ up to some arbitrary period $T$ (which can be very large).\n",
    "\n",
    "We will refer to this as \"simulating\" the model, as discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Third, since the value function is ex-ante unknown, we need to solve the Bellman equation for $V$. While functional equations can be tricky to work with in general, it turns out that the Bellman equation is computationally very convenient, and there are efficient algorithms to find $V$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As a result, dynamic optimization problems can be much easier to solve using the Bellman equation than a sequential formulation (and in some cases, it is the only option)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To summarize, rather than computing the optimal plan explicitly in one large optimization problem, we compute it recursively solving a *small-scale, finite-dimensional optimization problem in every period*. This is not only more computationally efficient in many cases, it sometimes may also be the only way to find the optimal plan, for example under uncertainty.\n",
    "\n",
    "Of course, a prerequisite for this strategy is knowing the value function $V$. We turn to how do this in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that another advantage of solving an intertemporal optimization problem using stationary dynamic programming is that the solution can be represented by a time-invariant *policy function* (*decision rule*) $\\phi: X \\rightarrow Y$. \n",
    "\n",
    "That is, $\\phi(x)$ gives the optimal value to choose for a given value of the state variable $x$, independent of the time period $t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a given value function $V$, the policy function is defined implicitly by\n",
    "\n",
    "\\begin{equation}\n",
    "    V(x)  =  U(x, \\phi(x)) + \\beta V\\big(F(x, \\phi(x))\\big)\\quad \\forall x \\in X.\n",
    "\\end{equation}\n",
    "\n",
    "This equation simply follows from the fact that $\\phi(x)$ is the optimal policy, so when $y = \\phi(x)$, the RHS of the Bellman eqution reaches the optimal value $V(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, if an optimal plan solves the sequential problem, it can be expressed as a policy function that solves the maximization problem associated with the Bellman equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As before, the intuition for $\\phi$ not depending on time is that the instantaneous payoff function does not depend on time in a stationary problem.\n",
    "\n",
    "We will see below how to find the policy function(s) numerically and how to use them to find the optimal plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As a final remark, dynamic programming and using the Bellman equation is not restricted to stationary infinite-horizon intertemporal optimization problems. Models that are not stationary (and cannot be transformed into a stationary version) can be solved using the following Bellman equation:\n",
    "\n",
    "\\begin{equation}\n",
    "    V_t(x_t)  =  \\max_{ y_t \\in G(t, x_t) }  U(x_t, y_t) + \\beta V_{t+1}(x_{t+1}), \\quad \\forall x_t \\in X_t\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In contrast to above, the value function here depends on time, and hence you have different value functions on the left-hand and the right-hand side. This also implies that we have time-dependent policy functions $\\phi_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a model with a finite time horizon $T$, we can use this equation to solve the model via *backwards induction*. \n",
    "\n",
    "That is, we start with $V_{T+1} = 0$ - since the economy ends after period $T$ - plug this in on the right hand side of the Bellman equation and solve for $V_T$. Next, we use $V_T$ on the RHS and solve for $V_{T-1}$ and so on. We continue this recursive procedure until $V_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a non-stationary, infinite-horizon problem, there is no last period, and hence applying backwards induction is less straightforward. \n",
    "\n",
    "To solve such models, we usually assume that they become stationary at some point $\\bar{T}$ in the future; starting in this period, we compute the value function $V( \\bar{T} )$ using the methods presented below. We can initialize backwards induction by setting $V_{T+1} = \\bar{V}$ and then again going backwards in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'vfi'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Value Function Iteration\n",
    "\n",
    "The next question is how to find the value function $V$, starting from the Bellman equation:\n",
    "\n",
    "\\begin{equation}\n",
    "    V(x)  =  \\max_{ y \\in G(x) }  U(x, y) + \\beta V(x^+)\n",
    "\\end{equation}\n",
    "\n",
    "s.t. $x^+ = F(x, y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before moving on, note that the Bellman equation is often expressed as \n",
    "\n",
    "\\begin{equation}\n",
    "    V  = \\mathcal{T}V\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\mathcal{T}$ is a mapping (also referred to as an \"operator\") which is applied on a function. Recall that a function is a mapping in a (finite-dimensional) Euclidean space that maps a scalar/vector $x$ to a scalar/vector $y$. Similarly, an operator is a mapping in an infinite-dimensional *metric* space that maps a function $w$ to a function $z$. \n",
    "\n",
    "The Bellman equation then implies that $\\mathcal{T}$ maps $V$ onto itself. In other words, $V$ is a *fixed point* of $\\mathcal{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It turns out that in order to find this fixed point, we can use an iterative procedure, an idea that we have already encountered in previous lectures. \n",
    "\n",
    "As a reminder, the basic idea of iterative methods is to generate a sequence of approximations to the object of interest, here the value function, i.e. to generate $\\left\\{ V^{(k)} \\right\\}_{k = 0}^\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These approximations should converge, i.e. become more and more \"precise\" with an increasing number of iterations. \n",
    "\n",
    "\\begin{equation}\n",
    "    V^{(k)} \\ \\rightarrow\\ V \\quad \\text{as} \\quad k\\ \\rightarrow\\ \\infty. \n",
    "\\end{equation}\n",
    "\n",
    "When we talked about iterative methods in previous lectures, the object of interest was a scalar or a vector, i.e. a finite-dimensional object. Here, we aim to approximate an infinite-dimensional function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The iteration rule is \n",
    "\n",
    "\\begin{equation}\n",
    "    V^{(k+1)} = \\mathcal{T} V^{(k)}. \n",
    "\\end{equation}\n",
    "\n",
    "In other words, we take the current guess $V^{(k)}$ and use it to solve the RHS side of the Bellman equation (that is, apply the operator $\\mathcal{T}$). The resulting value function is used as the new guess $V^{(k+1)}$:\n",
    "\n",
    "\\begin{equation}\n",
    "    V^{(k+1)}(x)  =  \\max_{ y \\in G(x) }  U(x, y) + \\beta V^{(k)}\\big(F(x, y)\\big)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we know that that the sequence $\\left\\{ V^{(k)} \\right\\}$ generated in this way converge to the true value function? We are guaranteed convergence if the operator $\\mathcal{T}$ is a *contraction mapping*. In the interest of time, we will not go deeper into this, but take this convergence as given. \n",
    "\n",
    "Next, we discuss how to implement *value function iteration* numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'ngm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### VFI: Numerical Implementation\n",
    "\n",
    "As mentioned above, a function is an infinite-dimensional object, hence we have to find a way to represent it on the computer with a finite-dimensional object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fortunately, we have already encountered a way to do this in the context of function approximation: recall that the approximant $\\hat{f}$ to a function $f$ is a linear combination of (a finite number of) basis functions, with (a finite number of) basis coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hence, when numerically implementing value function iteration, the value function will be represented by a vector of basis coefficients (and a given set of basis functions), which will be updated in every iteration. Formally,\n",
    "\n",
    "\\begin{equation}\n",
    "   V^{(k)}(x) \\approx \\hat{V}(x; a^{(k)}) = \\sum_{j = 0}^{n} a^{(k)}_j B_j(x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, the objective below is to find $a$ such that $\\hat{V}(x; a)$ is an approximation to the \"true\" value function that satisfies the Bellman equation. Hence, $\\hat{V}(x; a)$ should \"approximately\" satisfies the Bellman equation for all $x \\in X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This leads to the following pseudo-code:\n",
    "\n",
    "(i) Choose the approximation grid $\\{x_i : 1 \\le i \\le m\\} \\subset \\mathbb{R}^M$. Moreover, choose a degree of approximation $n$ and a family of basis functions $\\{B_j(x) : 0 \\le j \\le n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(ii) Choose an initial value for the basis coefficients $\\{a_j : 0 \\le j \\le n\\}$, denoted by $a_j^{(0)}$. The initial guess for the value function $V$ is approximated by \n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{V}^{(0)} = \\hat{V}(x; a^{(0)}) = \\sum_{j = 0}^{n} a^{(0)}_j B_j(x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(iii) *Optimization step*: for a given vector $a^{(k)}$, compute \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    v_i &= \\max_{ y \\in G(x_i) }  U(x_i, y) + \\beta \\hat{V}^{(k)}\\big(F(x_i, y)\\big) \\\\\n",
    "        &=  \\max_{ y \\in G(x_i) }  U(x_i, y) + \\beta \\sum_{j = 0}^{n} a^{(k)}_j B_j\\big(F(x_i, y)\\big)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "for each approximation node $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(iv) *Fitting step*: given the data $\\{x_i, v_i:  1 \\le i \\le m\\}$, use an appropriate approximation method to find $a^{(k+1)}$ such that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{V}(x_i; a^{(k + 1)}) \\approx v_i \n",
    "\\end{equation}\n",
    "\n",
    "Note that this last expression would feature an equality in the case of interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(v) *Stopping rule*: compute the convergence criterion $\\epsilon$ which compares the new guess $a^{(k + 1)}$ with the current guess $a^{(k)}$, i.e. is a function of these two vectors. If the convergence criterion is less than some small number, e.g. the square root of machine epsilon,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon(a^{(k)}, a^{(k + 1)}) \\le \\sqrt{\\epsilon_{DP}}\n",
    "\\end{equation}\n",
    "\n",
    "then stop and report $a^{(k + 1)}$. Otherwise, go back to (iii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before moving to the actual Python implementation, note that each iteration features two essential operations: optimization and function approximation. For both of them, we have learned efficient and reliable methods earlier in this course. \n",
    "\n",
    "Below, we will use the BFGS method for the optimization problem in the Bellman equation, and Chebyshev polynomials and nodes to approximate the value function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Workhorse Example: NGM\n",
    "\n",
    "We now use this algorithm to solve the NGM, as outlined above. From the mapping between the NGM and the general intertemporal optimization problem outlined above, we can write the Bellman equation for the NGM as:\n",
    "\n",
    "\\begin{equation}\n",
    "    V(k_t)  =  \\max_{ h_t \\in [0, \\infty), \\ k_{t+1} \\in [0, f(k_t, h_t) + (1 - \\delta) k_t) }  u(f(k_t, h_t) + (1 - \\delta) k_t - k_{t+1}, h_t) + \\beta V(k_{t+1})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We start by defining the parameters and some auxiliary functions. We then compute the steady state, as seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## utility\n",
    "beta = 0.8      # discount factor\n",
    "nu = 2       # risk-aversion coefficient for consumption\n",
    "eta = 1         # elasticity parameter for labor supply\n",
    "\n",
    "## production\n",
    "alpha = 0.25\n",
    "delta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "## derived\n",
    "A = (1 - beta * (1 - delta))/(alpha*beta) # normalization parameter for production function => steady state k = 1\n",
    "B = (1 - alpha) * A * (A - delta)**(-nu)      # parameter for utility function\n",
    "\n",
    "params = {'beta': beta, 'nu': nu, 'eta': eta, \n",
    "          'alpha': alpha, 'delta': delta, 'A': A, 'B': B }\n",
    "print( params['beta'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def u(c, h, pm):\n",
    "    \"\"\"\n",
    "    Evaluates an additive-separable utility function with consumption and labor as arguments\n",
    "    \"\"\"\n",
    "    return c**(1 - pm['nu'])/(1 - pm['nu']) - pm['B'] * h**(1 + pm['eta'])/(1 + pm['eta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def f(k, h, pm):\n",
    "    \"\"\"\n",
    "    Evaluates a Cobb-Douglas production function with coefficient alpha and shift parameter A, for two inputs k and h\n",
    "    \"\"\"\n",
    "    return pm['A'] * k**pm['alpha'] * h**(1 - pm['alpha'])\n",
    "\n",
    "\n",
    "def f_diff(k, h, pm):\n",
    "    \"\"\"\n",
    "    Evaluates the first derivatives (returned as a tuple) of the Cobb-Douglas function with coefficient alpha and shift parameter A, for two inputs k and h\n",
    "    \"\"\"\n",
    "    return (pm['alpha'] * f(k, h, pm) / k, (1 - pm['alpha']) * f(k, h, pm) / h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Compute Steady State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def steady(x, pm):\n",
    "    \"\"\"\n",
    "    Returns the vector-valued function consisting of the steady-state conditions \n",
    "    \"\"\"\n",
    "    y = np.zeros(2)\n",
    "    mp = f_diff(x[0], x[1], pm)\n",
    "    \n",
    "    y[0] = pm['beta'] * (mp[0] + 1 - pm['delta']) - 1\n",
    "    y[1] = ( f(x[0], x[1], pm) - pm['delta'] * x[0])**(- pm['nu']) * mp[1] - B * x[1]**pm['eta']\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000086 0.9999999999999751\n"
     ]
    }
   ],
   "source": [
    "## solve for steady state\n",
    "x0 = np.array([0.5, 0.5])\n",
    "res = scipy.optimize.root(steady, x0, args = ( params ), tol = 1e-8, method = \"broyden1\")\n",
    "kss, hss = res.x \n",
    "print(kss, hss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Interpolation grid and initial guess\n",
    "\n",
    "We can now implement the steps in the VFI algorithm. For the interpolation grid, we set $m = 10$. For the end points, note that since our initial capital stock is $k_0 = 0.8$ and its steady state value 1, we can focus on values for $k_t$ between $0.7$ and $1.3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "k_min = 0.7\n",
    "k_max = 1.3\n",
    "\n",
    "k_grid = fa.chebgrid(k_min, k_max, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We use an interpolation scheme, and hence $n = m - 1$. As an initial guess for the basis coefficients, $a^{(0)}$, a common choice is start with a vector of zeros; note that this would imply that the initial guess for the approximated continuation function, $\\hat{V}^{(0)}$, is zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, this may not be the best choice: for more computationally intensive problems, we want our initial guess to be as close to the true value function as possible, in order to minimize the number of iterations and hence the running time of the algorithm above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover, in the NGM, note that if the continuation value on the RHS of the Bellman equation is zero, this also implies that the control variable $k_{t+1}$ is set to zero for all state variables; intuitively, there is no reason to build up capital for the next period if it doesn't give you any utility. \n",
    "\n",
    "$k_{t+1} = 0$ would imply a capital stock outside of our grid, which causes problems when approximating the continuation value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a better initial guess, consider the special case of the NGM with logarithmic utility and full capital depreciation. We know that in this case, consumption and savings are a fixed share of output in every period. We can derive the value function in this case as\n",
    "\n",
    "\\begin{equation}\n",
    "    V(k) = \\frac{\\alpha}{1 - \\alpha \\beta} \\log(k) + Q\n",
    "\\end{equation}\n",
    "\n",
    "where $Q$ is a constant depending on the model parameters. We can use the first term as an initial guess for our value function in the more general case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## set the degree of approximation\n",
    "n = m - 1\n",
    "\n",
    "## initial guess for VF\n",
    "V0 = (alpha / (1 - alpha * beta)) * np.log(k_grid )\n",
    "## compute implied basis coefficients\n",
    "a0 = fa.chebapprox(V0, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Optimization Step\n",
    "\n",
    "For the optimization step (iii) in the VFI algorithm, it is useful to define a function that contains the objective function of the optimization problem on the right hand side of the Bellman equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def vf_rhs(x, k, a, k_min, k_max, pm):\n",
    "    \"\"\"\n",
    "    RHS of the Bellman equation\n",
    "    \"\"\"\n",
    "    kp = np.exp(x[0])\n",
    "    h = np.exp(x[1])\n",
    "    \n",
    "    current_util = u(f(k, h, pm) + (1 - pm['delta']) * k - kp, h, pm)\n",
    "    cont_value = np.polynomial.chebyshev.chebval(fa.chebconvert(kp, k_min, k_max), a)\n",
    "\n",
    "    return - (current_util + pm['beta'] * cont_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use Scipy's **minimize** function with the BFGS method to solve the problem on the RHS of the Bellman equation. Recall that we need to run a separate optimization for each of the $m$ grid point, which correspond to different initial capital stocks. We can use a **for** loop that iterates over **k_grid**:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n",
      "Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": [
    "x0 = (0, 0)\n",
    "V = np.zeros(m) \n",
    "\n",
    "for (ind, k) in enumerate(k_grid):\n",
    "    ## optimization step\n",
    "    res = scipy.optimize.minimize(vf_rhs, x0, args = (k, a0, k_min, k_max, params), method ='BFGS') \n",
    "    V[ind] = - res.fun\n",
    "    print(res.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to better structure our code below, it is useful to implement the steps above as a Python function, here called **opt_step**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def opt_step(k_grid, obj_fun, x0, a_ch, k_min, k_max, pm):     \n",
    "    \"\"\"\n",
    "    Function that loops over all states (= elements in k_grid) and solves the respective optimization problem (obj_fun, initial guess x0)\n",
    "    for a given vector of Chebyshev basis coefficients a_ch\n",
    "    -> uses Scipy's optimize module\n",
    "    \"\"\"\n",
    "    ## initialize policy and value functions\n",
    "    V = np.zeros(m)\n",
    "    Kp = np.zeros(m)\n",
    "    H = np.zeros(m)\n",
    "    \n",
    "    ## loop\n",
    "    for (ind, k) in enumerate(k_grid):\n",
    "    ## optimization step\n",
    "        res = scipy.optimize.minimize(obj_fun, x0, args = (k, a_ch, k_min, k_max, pm), method ='BFGS') \n",
    "        V[ind] = - res.fun\n",
    "        Kp[ind], H[ind] = np.exp( res.x )\n",
    "\n",
    "    return V, Kp, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Fitting Step\n",
    "\n",
    "The optimization step returns the \"new\" value function $v_i$ - given the continuation value $\\beta \\hat{V}^{(k)}$ computed with the current guess $a^{(k)}$ - for each of the $m$ grid points $k_i$. \n",
    "\n",
    "Since **k_grid** was defined as a Chebyshev grid and the continuation value was approximated with a Chebyshev basis, we can use our **chebapprox** function on the data $\\{k_i, v_i:  1 \\le i \\le m\\}$ to find the \"new\" guess $a^{(k + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "a = fa.chebapprox(V, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Outer Loop\n",
    "\n",
    "As outlined in the algorithm above, we iterate on the optimization and on the fitting step until\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon(a^{(k)}, a^{(k + 1)}) \\le \\sqrt{\\epsilon_{DP}}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon$ denotes the convergence criterion as a function of the new and current iterates for the basis coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The easiest approach would be to compute the norm of the distance between $a^{(k)}$ and  $a^{(k + 1)}$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon(a^{(k)}, a^{(k + 1)}) = \\left|\\left|\\ a^{(k)} - a^{(k + 1)}\\ \\right|\\right|\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As in the other instances of iterative procedures that we have seen in previous lectures, we can use a **while** loop to iterate until the convergence criterion is sufficiently small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 8.018930411734804e-09\n"
     ]
    }
   ],
   "source": [
    "## initialize initial guess for basis coefficients and optimization\n",
    "a_ch = a0.copy()\n",
    "x0 = (0, 0)\n",
    "\n",
    "eps = 1\n",
    "it = 0\n",
    "maxit = 100\n",
    "\n",
    "while eps > 1e-8 and it < maxit:\n",
    "    it += 1\n",
    "    ## optimization step\n",
    "    V, K, H = opt_step(k_grid, vf_rhs, x0, a_ch, k_min, k_max, params)\n",
    "    ## fitting step\n",
    "    a_new = fa.chebapprox(V, n)\n",
    "    ## compute convergence criterion\n",
    "    eps = np.linalg.norm(a_new - a_ch)\n",
    "    ## update coefficients\n",
    "    a_ch = a_new.copy()\n",
    "\n",
    "print(it, eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following piece of code repeats this last step, while plotting the approximated value function for every iteration. \n",
    "\n",
    "The graph illustrates convergence, in the sense that the distance between two iterates of value function decreases in the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "a_ch = a0.copy()\n",
    "eps = 1\n",
    "it = 0\n",
    "maxit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(k_grid, V0)\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('V')\n",
    "\n",
    "while eps > 1e-8 and it < maxit:\n",
    "    it += 1\n",
    "    ## optimization step\n",
    "    V, K, H = opt_step(k_grid, vf_rhs, x0, a_ch, k_min, k_max, params)\n",
    "    ax.plot(k_grid, V)\n",
    "    ## fitting step\n",
    "    a_new = fa.chebapprox(V, n)\n",
    "    ## compute convergence criterion\n",
    "    eps = np.linalg.norm(a_new - a_ch)\n",
    "    ## update coefficients\n",
    "    a_ch = a_new.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Policy Functions and Simulation\n",
    "\n",
    "At this point, we have found the basis coefficients approximating the value function $V$ that satisfies the stationary Bellman equation. Recall that ultimately, we are interested in the optimal plan that solves the intertemporal optimization problem, here sequences over time for capital and labor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One way to generate these optimal sequences is to derive and apply the policy functions, as introduced above. Denote the policy functions by $\\phi_k$ and $\\phi_h$, respectively. Hence, we have\n",
    "\n",
    "\\begin{align}\n",
    "    k_{t+1} = \\phi_k(k_t) \\\\\n",
    "    h_t = \\phi_h(k_t)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In line with how we defined the policy functions above, they are the solutions to the optimization problem on the RHS of Bellman equation, assuming that we have found the true value function:\n",
    "\n",
    "\\begin{equation}\n",
    "    V(k)  =  u(f(k, \\phi_h(k)) + (1 - \\delta) k - \\phi_k(k), \\phi_h(k)) + \\beta V(\\phi_k(k))\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When running the optimization step in the **opt_step** function above, we also kept track of the optimal capital and labor supply in the arrays **'K'** and **'H'**. \n",
    "\n",
    "Since by construction, the last iteration in our outer loop solved the optimization problem with (an approximation of) the true value functions, these arrays now contain the optimal control variables along our grid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words, we have data $\\{k_i, \\phi_{k,i}:  1 \\le i \\le m\\}$ and $\\{k_i, \\phi_{h,i}:  1 \\le i \\le m\\}$, respectively. Hence, we can use function approximation to get the policy functions, again represented by a Chebyshev basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "a_k = fa.chebapprox(K, n)\n",
    "a_h = fa.chebapprox(H, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As a final step, we can use these approximations to generate the optimal plan, i.e. the optimal sequences for $k_{t+1}$ and $h_t$ over time, for an arbitrary number of periods $T$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## number of periods\n",
    "T = 30\n",
    "\n",
    "## initial capital stock\n",
    "k0 = 0.8\n",
    "\n",
    "## initialize arrays to keep track of time series\n",
    "kt = np.zeros(T+1)\n",
    "ht = np.zeros(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## initial capital stock is given\n",
    "kt[0] = k0\n",
    "\n",
    "## loop over time and use policy function approximations to fill kt and ht\n",
    "for t in range(T):\n",
    "    kt[t+1] = np.polynomial.chebyshev.chebval( \n",
    "                fa.chebconvert(kt[t], k_min, k_max), a_k )\n",
    "    ht[t] = np.polynomial.chebyshev.chebval( \n",
    "                fa.chebconvert(kt[t], k_min, k_max), a_h )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x237c8ae4ac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xU9Z3/8ddnJgm5EEhIAMP9IlgQBDHrvUqrdhGr1HXtr2y7atstdautrrvb9tftbl3b7q83d63bVmtbqu7We6vyU1ulror1DnIVBAERQgLhYgLhnsxn/5iTGGMSQmaSkznzfj4e85gz33NmzufLgXcO35z5HnN3REQkumJhFyAiIj1LQS8iEnEKehGRiFPQi4hEnIJeRCTicsIuoK3y8nIfM2ZM2GWIiGSUJUuW7HT3we2t63NBP2bMGBYvXhx2GSIiGcXM3uloXUpDN2Y238xqzWxVB+vNzG41s/VmtsLMZqSyPxEROXapjtHfCczqZP2FwITgMQ+4LcX9iYjIMUpp6MbdF5nZmE42mQPc7cmv375sZiVmVuHuNanstzMzZ87sqY+WEDngloPHc/BYTnLZYngsByyGx+K4xVueaX5tseR6i4NZ0GbQsi7ZBha0x4Ll5LrWy461tLW8btXm1vo1QVvyOfmg1ba81/a+dQSfy3vrjPdv1/Kyeft21rV+bR20d8DtaNsc/TPS8v5Ud9Nt6d9x4e51lG16+qjbPfvss2nfN/T8GP1wYEur11VB2/uC3szmkTzjZ9SoUT1ckvQWtxhNOQUkcgpIxPNI5PTD43kk4v2CR7Dc3B7Lw+O5eCyHRCwHjyWXPZaLx3N7pshEE0YC3MG93WXzBOBtliEZycn2lvVB7La04Zg7kAj2F7RB8F5ojmravH4vbtpu13aZYN8drPtAU3vTnnQ8FYp1eZqUHphOJSJTtOTtqw11/z0d9O39aPzAkXP3O4A7ACorK1M6sj31E1GSGpsSbN97iKrd+9m+9xC7Gw6xa9/h5KPhELv3HWZXQ/J1/YEjnX6WGfTvl8PAfjkU5+dS2C9OYV6cgtw4+cGjIDdOQV7z61jLurx4jLycGLnxGP2C5+RrIy8nRl482ZYTN3LjMeIxIzcWIx43cmLJRzxm2FHPXkUyX08HfRUwstXrEUB1D+9TUtDYlGDbnoNUvXsgeOxved5ad4CauoM0Jt7/szhmUFqYR1n/PMqK+jFp2ADKi/IYVNSPsv55lBTmUpyfS3F+DsVBqPfPz6EwN04spqAV6Wk9HfQLgGvN7D7gNKC+J8fn5djUHzjCmpo9rK7ew5qaPazZtod12xo43JRo2cYMhhbnM7y0gBmjShkxrYARpYWMKC1g6IB8yoryKCnMI67AFumzUgp6M7sXmAmUm1kV8C0gF8DdbweeAGYD64H9wGdT2Z9035bd+3mjup7V1XtYXbOXNTV72Fp3oGV9WVEek4cN4KqzxjCuvKglzCtK8umXEw+xchFJVapX3cw9ynoHrkllH9I9ew8e4aUNu1j01g6ef2sn7+zaDySHWcYN7s+M0aV8+vRRTK4YwOSKAQwu7qfxapGI6nPfjJXuaUo4K7fW8/y6HSx6awevb66jKeEU5sU5Y1wZV505hhmjSpk4tJiCPJ2hi2QTBX0G23vwCL9ftY3n1u3ghfU7qdt/BDOYMmwgXzxnHOdMHMyMUaXk5WjuOpFspqDPQKu21vObVzbz6LKt7D/cxNAB/Th/0lDOmTiYs8aXUda/X9glikgfoqDPEAcON/HYimp+88pmlm2pIz83xiXThvFXp41m2oiBGl8XkQ4p6Pu49bUN3PPKZh5asoU9Bxs5fkh/vnXxZP7i5BEMLOyhb4uKSKQo6PugxqYEf3hjG//98ju8vHE3uXFj1pQKPn3aKE4bO0hn7yJyTBT0fcySd97lnx9ZxeqaPYwoLeCrs07g8lNGMrhY4+4i0j0K+j5iV8Mhvv+HN3lgcRXHDcjnP+eezOypFfrGqYikTEEfsqaEc++rm/nhk2vZd6iRL54zjq+cN4Gifjo0IpIeSpMQLd9Sxz8/uooVVfWcPm4QN82ZwsShxWGXJSIRo6APQd3+w/zgybXc++pmyvv348efms4l04bpl6wi0iMU9L0okXAeXLKF7/3+TfYcbOSzZ47l+gsmMCBfl0mKSM9R0PeSg0ea+Mq9S3lq9XYqR5dy05wpTB42IOyyRCQLKOh7Qd3+w/zNXYtZsvldvnnRJD531ljdcENEeo2CvodtrTvAlfNfZfOu/fzn3JP5+EnDwi5JRLKMgr4HranZw1W/fpX9h5u463Oncsb4srBLEpEspKDvIS9t2MW8uxdT2C/Og1efwYeO03i8iIRDQd8DHltRzQ33L2dUWSF3fe5UhpcUhF2SiGQxBX2azf/T23z78dWcMqqUX15ZSUlhXtgliUiWU9CnSSLhfP8Pb/LzRRv58xOH8uNPnUx+rm7ZJyLhU9CnweHGBF99aDmPLKvmr08fzY2XnKjJyESkz1DQp8jd+bv7l/H4yhr+8c9P4Eszx2sqAxHpUxT0KbrzxU08vrKGr836EH87c3zY5YiIfEAs7AIy2dLN7/JvT6zh/ElDuPrccWGXIyLSLgV9N9XtP8y19yxlSHE+N18+XcM1ItJnaeimGxIJ5+8fWE7t3oM8ePWZukm3iPRpOqPvhjue38jTb9byT7MnMX1kSdjliIh0SkF/jF7btJsfPrmW2VOP48ozx4RdjojIUSnoj8GuhkNce8/rjCwt4HuXnaRxeRHJCAr6LmpKONffv4x39x/hp5+eobtCiUjGUNB30U+fWc/zb+3kxotP5MRhA8MuR0SkyxT0XfDC+p38xx/X8Ynpw5h76siwyxEROSYK+qOo3XOQ6+5byrjyIr576VSNy4tIxtF19J1obErw5XuX0nCokXu+cDpF/fTHJSKZR8nViVuffotX3t7Njy6fxsShxWGXIyLSLRq66UB13QFuf24jn5g+jL88ZUTY5YiIdFtKQW9ms8xsrZmtN7Ovt7N+tJk9bWYrzOxZM8uYxPzP/1mP4/zDn58QdikiIinpdtCbWRz4KXAhMBmYa2aT22z2I+Budz8JuAn4f93dX2/avGs/Dy7ewtxTRzGitDDsckREUpLKGf2pwHp33+juh4H7gDlttpkMPB0sP9PO+j7px0+/RTxmXPOR48MuRUQkZakE/XBgS6vXVUFba8uBy4LlS4FiMytr+0FmNs/MFpvZ4h07dqRQUurW1zbw8NIqrjhjNEMH5Idai4hIOqQS9O1dUO5tXv8DcK6ZLQXOBbYCjR94k/sd7l7p7pWDBw9OoaTU3fLHdeTnxrn6XN0tSkSiIZXLK6uA1l8THQFUt97A3auBvwAws/7AZe5en8I+e9Samj08tqKGaz4ynrL+/cIuR0QkLVI5o38NmGBmY80sD/gUsKD1BmZWbmbN+/i/wPwU9tfj/mPhOorzc5j3YZ3Ni0h0dDvo3b0RuBZ4ElgDPODub5jZTWZ2SbDZTGCtma0DhgLfTbHeHrOiqo6nVm/nb84epztGiUikpPTNWHd/AniiTdu/tFp+CHgolX30ln9fuI6Swlw+d/aYsEsREUkrfTMWWPLObp5du4Orzx1PseaZF5GIUdADNz+1jvL+eVxxxuiwSxERSbusD/oX1+/kxQ27+NLM4ynM0xxvIhI9WR307s7NC9dx3IB8/uq0UWGXIyLSI7I66J9bt4Ml77zLl887nvzceNjliIj0iKwNenfn5qfWMaK0gMtP0e0BRSS6sjbon1q9nZVb67nuvAnk5WTtH4OIZIGsTLhEwvmPhesYV17EpSe3nYdNRCRasjLoH19Zw5vb9nLd+RPIiWflH4GIZJGsSzl358dPv8UJQ4u5+KRhYZcjItLjsi7ol22pY31tA5//8FhisfZmWhYRiZasC/pHl1WTlxNj1pTjwi5FRKRXZFXQNzYleGxFDed9aAgDNKeNiGSJrAr6lzbuYmfDIeZM19i8iGSPrAr6R5dVU9wvh5knDAm7FBGRXpM1QX/wSBN/WLWNWVOO03QHIpJVsibon3mzloZDjcyZri9IiUh2yZqgf3RZNeX9+3HG+LKwSxER6VVZEfT1B47wP2truXhaBXFdOy8iWSYrgv7JN7ZxuDGhYRsRyUpZEfQLllUzuqyQaSMGhl2KiEivi3zQ1+45yIsbdjJn2jDMNGwjItkn8kH/2IoaEg6X6EtSIpKlIh/0jy6vZnLFAI4fUhx2KSIioYh00G/auY/lW+o05YGIZLVIB/2C5dUAXDxNQS8i2SuyQe/uPLJsK6eOHcSwkoKwyxERCU1kg/6N6j1s3LFPwzYikvUiG/QLlleTEzNmT6kIuxQRkVBFMugTCWfBsmrOnTiY0qK8sMsREQlVJIP+1U272bbnoK6dFxEhokH/6LJqCnLjXDB5aNiliIiELnJBf7gxwRMra/jYiUMpzMsJuxwRkdBFLugXrdtB/YEjutpGRCQQuaB/dHk1pYW5fHjC4LBLERHpEyIV9PsONbJw9TZmT60gNx6promIdFtKaWhms8xsrZmtN7Ovt7N+lJk9Y2ZLzWyFmc1OZX9Hs3D1dg4e0Q1GRERa63bQm1kc+ClwITAZmGtmk9ts9k3gAXc/GfgU8LPu7q8rHl22lWED86kcXdqTuxERySipnNGfCqx3943ufhi4D5jTZhsHBgTLA4HqFPbXqV0Nh1j01k4unj6MmO4LKyLSIpXrD4cDW1q9rgJOa7PNjcBTZvZloAg4v70PMrN5wDyAUaNGdauY3JwY35g9iXMnlnfr/SIiUZXKGX17p83e5vVc4E53HwHMBv7LzD6wT3e/w90r3b1y8ODuXS0zID+Xz589VjcYERFpI5WgrwJGtno9gg8OzXweeADA3V8C8gGdcouI9KJUgv41YIKZjTWzPJK/bF3QZpvNwHkAZjaJZNDvSGGfIiJyjMy97WjLMbw5ebnkLUAcmO/u3zWzm4DF7r4guArnF0B/ksM6X3X3p47ymTuAd7pdVPJ/DDtTeH9fEZV+gPrSV0WlL1HpB6TWl9Hu3u7Yd0pB3xeZ2WJ3rwy7jlRFpR+gvvRVUelLVPoBPdcXfX1URCTiFPQiIhEXxaC/I+wC0iQq/QD1pa+KSl+i0g/oob5EboxeRETeL4pn9CIi0oqCXkQk4iIT9EebMjmTmNkmM1tpZsvMbHHY9RwLM5tvZrVmtqpV2yAzW2hmbwXPGTG9aAd9udHMtgbHZllPT72dDmY2MpgufI2ZvWFm1wXtGXdcOulLJh6XfDN71cyWB33516B9rJm9EhyX+4MvpKa2ryiM0QdTJq8DLiA5NcNrwFx3Xx1qYd1kZpuASnfPuC+BmNk5QANwt7tPCdp+AOx29+8FP4RL3f1rYdbZFR305Uagwd1/FGZtx8LMKoAKd3/dzIqBJcAngKvIsOPSSV8+SeYdFwOK3L3BzHKBPwHXATcAv3P3+8zsdmC5u9+Wyr6ickbflSmTpRe4+yJgd5vmOcBdwfJdJP9h9nkd9CXjuHuNu78eLO8F1pCcfTbjjksnfck4ntQQvMwNHg58FHgoaE/LcYlK0Lc3ZXJGHvyAk5zeeUkwhXOmG+ruNZD8hwoMCbmeVF0b3DFtfiYMd7RmZmOAk4FXyPDj0qYvkIHHxcziZrYMqAUWAhuAOndvDDZJS5ZFJei7MmVyJjnL3WeQvHvXNcEQgvQNtwHjgelADXBzuOV0nZn1B34LXO/ue8KuJxXt9CUjj4u7N7n7dJKz/54KTGpvs1T3E5Wg78qUyRnD3auD51rgYZJ/ATLZ9mBstXmMtTbkerrN3bcH/zgTJCfsy4hjE4wB/xb4jbv/LmjOyOPSXl8y9bg0c/c64FngdKDEzJpvCpWWLItK0HdlyuSMYGZFwS+ZMLMi4GPAqs7f1ectAK4Mlq8EHg2xlpQ0B2PgUjLg2AS/9PsVsMbd/73Vqow7Lh31JUOPy2AzKwmWC0jegW8N8Azwl8FmaTkukbjqBtqfMjnkkrrFzMaRPIuH5K0e78mkvpjZvcBMktOtbge+BTxC8gY0o0jeo+Byd+/zv+TsoC8zSQ4POLAJ+GLzOHdfZWZnA88DK4FE0PwNkmPbGXVcOunLXDLvuJxE8petcZIn3Q+4+01BBtwHDAKWAp9x90Mp7SsqQS8iIu2LytCNiIh0QEEvIhJxCnoRkYjLOfomvau8vNzHjBkTdhkiIhllyZIlOzu6Z2yfC/oxY8aweHFGzeMlIhI6M3uno3UauhERibjIBP2RpgTPrq2lpv5A2KWIiPQpkQn62r2HuOrXr/G717eGXYqISJ8SmaAfXlLA9JElPLGyT38ZTkSk10Um6AEumlrBG9V7eGfXvrBLERHpMyIV9BdOPQ6Ax3VWLyLSIlJBP6K0kGkjS3h8hYJeRKRZpIIe4KKpx2n4RkSklcgF/eypyWmpNXwjIpIUuaBvHr7R1TciIkmRC3pIDt+s2rqHzbv2h12KiEjoIhn0F07R8I2ISLNIBv3IQYVMGzFQwzciIkQ06CH5S9mVW+s1fCMiWS/SQQ/wxCqd1YtIdjtq0JvZfDOrNbNVHaw3M7vVzNab2Qozm9Fm/QAz22pmP0lX0V0xclAhJ2n4RkSkS2f0dwKzOll/ITAheMwDbmuz/tvAc90pLlWzp1awoqqeLbs1fCMi2euoQe/ui4DdnWwyB7jbk14GSsysAsDMTgGGAk+lo9hjdVHz8I3O6kUki6VjjH44sKXV6ypguJnFgJuBfzzaB5jZPDNbbGaLd+zYkYaSkkYOKmTqcA3fiEh2S0fQWzttDnwJeMLdt7Sz/v0bu9/h7pXuXjl4cLv3tu222VMrWK7hGxHJYukI+ipgZKvXI4Bq4AzgWjPbBPwIuMLMvpeG/R2T5uGb3+vqGxHJUukI+gUkQ9zM7HSg3t1r3P3T7j7K3ccA/0ByHP/radjfMRlVVsiU4QN4fOW23t61iEif0JXLK+8FXgJOMLMqM/u8mV1tZlcHmzwBbATWA78gOWTTp8yeWsHyLXVUvavhGxHJPjlH28Dd5x5lvQPXHGWbO0lephmKi6ZW8IM/rOX3K7fxhXPGhVWGiEgoIvvN2NZGlxVx4rABmuRMRLJSVgQ9wEUnVbBsSx1b6w6EXYqISK/KnqBvvvpGZ/UikmWyJug1fCMi2Sprgh6SV98s3azhGxHJLlkV9Bq+EZFslFVBP6a8iMkVGr4RkeySVUEPyatvlm6uo1rDNyKSJbIu6JvvPPX4Cp3Vi0h2yLqgH1teROXoUua/8DYHjzSFXY6ISI/LuqAHuP78idTUH+T+1446g7KISMbLyqA/6/gyTh07iJ8+s15n9SISeVkZ9GbGDRdMpHbvIf775XfCLkdEpEdlZdADnD6ujLOOL+P25zaw/3Bj2OWIiPSYrA16gBsumMjOhsPc/ZLO6kUkurI66E8ZPYhzJw7m589toOGQzupFJJqyOugB/u6Ciby7/wh3vvB22KWIiPSIrA/66SNLOH/SEO5YtJE9B4+EXY6ISNplfdBD8rr6PQcb+dXzOqsXkehR0ANThg9k1onHMf9Pb1O3/3DY5YiIpJWCPnD9BRNoONzIL57fGHYpIiJppaAPfOi4AVw0tYJfv7CJ3ft0Vi8i0aGgb+X68ydw4EgTP39uQ9iliIikjYK+leOHFDNn2jDuemkTO/YeCrscEZG0UNC3cd35EznS5Nyus3oRiQgFfRtjy4u49OTh/PfL77B9z8GwyxERSZmCvh1f+egEmhLOz55ZH3YpIiIpU9C3Y1RZIZdXjuDeV7ewVfeWFZEMd9SgN7P5ZlZrZqs6WG9mdquZrTezFWY2I2ifbmYvmdkbQfv/SXfxPenaj07AcW5+am3YpYiIpKQrZ/R3ArM6WX8hMCF4zANuC9r3A1e4+4nB+28xs5Lul9q7hpcUcPW54/nd61t5aElV2OWIiHTbUYPe3RcBuzvZZA5wtye9DJSYWYW7r3P3t4LPqAZqgcHpKLq3XHfeBM4cX8Y/PbyS1dV7wi5HRKRb0jFGPxxofZftqqCthZmdCuQB7V6zaGbzzGyxmS3esWNHGkpKj5x4jFvnnkxJYS5/+5sl1B/Q7JYiknnSEfTWTpu3rDSrAP4L+Ky7J9r7AHe/w90r3b1y8OC+ddJf3r8fP/v0DLa+e4C/f2A5iYQf/U0iIn1IOoK+ChjZ6vUIoBrAzAYAjwPfDIZ1MtIpowfxTxdN4o9rtvPzRZr0TEQySzqCfgFwRXD1zelAvbvXmFke8DDJ8fsH07CfUF115hg+flIFP3zyTV7csDPsckREuqwrl1feC7wEnGBmVWb2eTO72syuDjZ5AtgIrAd+AXwpaP8kcA5wlZktCx7T09+F3mFmfP+ykxg3uD9fuXcp2+r1rVkRyQzm3rfGnCsrK33x4sVhl9Gh9bV7ueQnLzCpYgD3zTud3Li+cyYi4TOzJe5e2d46pdQxOn5IMd+/7CSWvPMu//bEmrDLERE5KgV9N1w8bRifPWsMv35hE/9/eXXY5YiIdEpB303fmD2JytGlfO23K1hfuzfsckREOqSg76bceIyf/NUMCvPifPG/ltBwqDHskkRE2qWgT8FxA/O5de7JvL1zHzfcv4xDjU1hlyQi8gEK+hSdOb6cf/n4ZJ5avZ2//uWrvKsbi4tIH6OgT4OrzhrLrXNPZllVHX9x24u8vXNf2CWJiLRQ0KfJJdOGce8XTqP+wBEu/dkLvPp2ZxN+ioj0HgV9Gp0yehAPf+lMBhXl8ZlfvsIjS7eGXZKIiII+3UaXFfHw357FjNElXH//Mm754zr62rePRSS7KOh7wMDCXO7+3GlcNmMEt/zxLW54YLmuyBGR0OSEXUBU5eXE+NHlJzGmrJCbF65ja90Bfv6ZUygtygu7NBHJMjqj70FmxpfPm8CPPzWdZZt1RY6IhENB3wvmTB/OPV84jbr9h7nkJ3/il89v5HBjuzfbEhFJOwV9L6kcM4hHrzmbk0eV8p3H1zDrlkU8vWa7flErIj1OQd+LRpUVctdn/4xfX/VnYPD5uxZzxfxXWbddk6KJSM9R0PcyM+MjHxrCk9efw798fDLLt9Qx65ZF/PMjq9it6RNEpAco6EOSG4/xubPH8tw/foTPnD6ae17dzMwfPsOv/vS2xu9FJK0U9CErLcrjpjlT+P11H2bayBK+/dhqZt2yiIWrt5NIaPxeRFKne8b2Ie7OM2tr+c5ja9i4cx8jBxVw+SkjueyUEQwvKQi7PBHpwzq7Z6yCvg863JjgiZU1PLhkCy+s34UZnH18OZ+sHMkFk4eSnxsPu0QR6WMU9Blsy+79PLSkioeWVLG17gADC3L5xPRhXF45kinDB4Zdnoj0EQr6CEgknBc37OLBJVv4/aptHG5MMKliAJefMoKPfmgIo8sKMbOwyxSRkCjoI6Z+/xEWrKjmwcVbWFFVD8CwgfmcPr6MM8eXc8b4Mo3pi2QZBX2EbdzRwAsbdvHyhl28tHFXy7X4o8sKOWNcGWeMTz6GFOeHXKmI9CQFfZZIJJy12/fy0oZdvLhhF6+8vYu9BxsBGD+4iJNGlDBxaDEnHNefiUOLGV5SoOEekYhQ0GeppoTzRnU9L23Yxcsbd/Hmtr3U1B9sWd+/Xw4ThvbnhKHFwQ+A5HN5/zz9ABDJMAp6aVF/4Ahvbd/L2u17WbdtL29u28u67Xt5d/+Rlm2K8uIMKymgoqSA4SX5VAwsYFhJAcMG5jOspIDjBubrEk+RPqazoD/qjUfMbD7wcaDW3ae0s96AHwOzgf3AVe7+erDuSuCbwabfcfe7utcFSZeBBblUjhlE5ZhBLW3uzo6GQ6zb1sDa7XvZsns/NfUHqK47yOrqenY2fHAOnvL+eQwuzmdQUS6lhXkMKsp777koj9LC99pLCnMpyI3rfwkiIenKHabuBH4C3N3B+guBCcHjNOA24DQzGwR8C6gEHFhiZgvc/d1Ui5b0MjOGFOczpDifsyeUf2D9wSNNbKs/SHXdAbbWHaAmWN7ZcIjd+w5TXbeH3fsOU3/gSDufnhQzKOqXQ/9+OS3P/d/3Ok5Rvxzyc+Pk58aSzzlx+jUv58bJz0ku98uNkRePkRuPkZeTfM6NW/J1PEYsph8oIq0dNejdfZGZjelkkznA3Z4cA3rZzErMrAKYCSx0990AZrYQmAXcm2rRnZk5c2ZPfrx0oBQowUjkFNCUW0AiJ5+mnEISwXIilkcinsfeeB718eSyB88ty7E8iKVhSMgTWKIJvAnzBLgnn0kEr5PPzcu4Y3jQ7oAHbcl1eAILPve9dZ48fSG5fev3BUUE7wnaW5ZJvrfV65b1LZ/ZapuWbVtv977OJrdvd723u9jZ5zSzjld1oieGgbv4maGNQHdtx7kHdlFYv+mo2z377LOpldOBdNwzdjiwpdXrqqCto/YPMLN5wDyAUaNGpaEkCYPhxBv3E2/c3+3PcAyP5bzvkYjlfqDNLQYWx2Nx3IJHLGhr1Y5ZsG3s/c/EcLP3tYMl24hBLEbCDLDkZxADa14OYjBY7y1DUq22DV7SdttW27X+k8N473Np9b6W97b9LMkkRTve6FLQ95R0BH17f+u8k/YPNrrfAdwByV/GplJMT/1EFOmr3L3lPwfeqq1l/fu2bW7zD7S1/9ldrOEYTqm7/pld/bxwTuePZa+5sVkU5H21x2o5mnQEfRUwstXrEUB10D6zTfuzadifiLRiZu2c5OusX96TjvnoFwBXWNLpQL271wBPAh8zs1IzKwU+FrSJiEgv6srllfeSPDMvN7MqklfS5AK4++3AEyQvrVxP8vLKzwbrdpvZt4HXgo+6qfkXsyIi0nv63BemzGwH8E4KH1EO7ExTOWGKSj9AfemrotKXqPQDUuvLaHcf3N6KPhf0qTKzxR19OyyTRKUfoL70VVHpS1T6AT3XF90zVkQk4hT0IiIRF8WgvyPsAtIkKv0A9aWvikpfotIP6KG+RG6MXkRE3i+KZ/QiItKKgl5EJOIiE/RmNsvM1prZejP7etj1pMLMNpnZSjNbZmYZdRcWM5tvZrVmtqpV2yAzW2hmbwXPpWHW2FUd9OVGM9saHJtlZjY7zBq7wsxGmtkzZrbGzN4ws3A65gUAAALkSURBVOuC9ow7Lp30JROPS76ZvWpmy4O+/GvQPtbMXgmOy/1mlpfyvqIwRm9mcWAdcAHJOXZeA+a6++pQC+smM9sEVLp7xn0JxMzOARpITl09JWj7AbDb3b8X/BAudfevhVlnV3TQlxuBBnf/UZi1HYtg2vAKd3/dzIqBJcAngKvIsOPSSV8+SeYdFwOK3L3BzHKBPwHXATcAv3P3+8zsdmC5u9+Wyr6ickZ/KrDe3Te6+2HgPpLz5Esvc/dFQNupLuYAzXcXu4vkP8w+r4O+ZBx3r2m+65u77wXWkJwyPOOOSyd9yTie1BC8zA0eDnwUeChoT8txiUrQd3nu+wzhwFNmtiSYqz/TDQ0muiN4HhJyPam61sxWBEM7fX64o7XgJkInA6+Q4celTV8gA4+LmcXNbBlQCywENgB17t4YbJKWLItK0Hd57vsMcZa7zyB5m8ZrgiEE6RtuA8YD04Ea4OZwy+k6M+sP/Ba43t33hF1PKtrpS0YeF3dvcvfpJKdxPxWY1N5mqe4nKkHf0Zz4Gcndq4PnWuBhkn8BMtn2YGy1eYy1NuR6us3dtwf/OBPAL8iQYxOMAf8W+I27/y5ozsjj0l5fMvW4NHP3OpL36zgdKDGz5pmF05JlUQn614AJwW+r84BPkZwnP+OYWVHwSybMrIjkPP6rOn9Xn7cAuDJYvhJ4NMRaUtIcjIFLyYBjE/zS71fAGnf/91arMu64dNSXDD0ug82sJFguAM4n+TuHZ4C/DDZLy3GJxFU3AMHlVLcAcWC+u3835JK6xczGkTyLh+T9Au7JpL60vn8BsJ3k/QseAR4ARgGbgcsz4d4EHfRlJsnhAQc2AV9sHufuq8zsbOB5YCWQCJq/QXJsO6OOSyd9mUvmHZeTSP6yNU7ypPsBd78pyID7gEHAUuAz7n4opX1FJehFRKR9URm6ERGRDijoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIR978nHU61TjfxaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot optimal plans and check for convergence to steady state\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(range(T), kt[:-1])\n",
    "ax[0].hlines(kss, 0, T)\n",
    "ax[1].plot(range(T), ht)\n",
    "ax[1].hlines(hss, 0, T)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Final Remark\n",
    "\n",
    "The numerical algorithm presented above is just one way to implement dynamic programming/value function iteration. Other approaches are possible in particular with how to approximate the value function and how to implement the optimization step. \n",
    "\n",
    "In particular, easier algorithms may \"discretize\" the state space (i.e. compute the value function along a very dense grid for $k_i$) or use piecewise linear interpolation rather than Chebyshev polynomials (cp. problem set 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, these methods may not only be considerably slower than the algorithm presented here, they can also be much less accurate. \n",
    "\n",
    "For most of the intertemporal optimization problems encountered in economics, the combination of (Chebyshev) polynomial approximation and Newton-based optimization methods (in contrast to, e.g., bisection or Nelder-Mead) is *the best we can do*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "<a id = 'appendix'></a>\n",
    "\n",
    "## Appendix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Principle of Optimality\n",
    "\n",
    "Start with the definition of the value function:\n",
    "\n",
    "\\begin{equation}\n",
    "    V^*(x_0)  = \\sum^\\infty_{t = 0} \\beta^t U(x^*_t, y^*_t) \n",
    "\\end{equation}\n",
    "\n",
    "Noting that the optimal state in the first period is constrained by the initial state, $x^*_0 = x_0$, the last expression can be rewritten as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    V^*(x_0)  &= \\sum^\\infty_{t = 0} \\beta^t U(x^*_t, y^*_t) \\\\\n",
    "              &= U(x^*_0, y^*_0) + \\sum^\\infty_{t = 1} \\beta^t U(x^*_t, y^*_t) \\\\\n",
    "              &= U(x_0, y^*_0) + \\beta \\sum^\\infty_{t = 0} \\beta^t U(x^*_{t+1}, y^*_{t+1}) \n",
    "              &= U(x_0, y^*_0) + \\beta V^*(x^*_{1}) \n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This equation encapsulates the basic idea of dynamic programming: an optimal plan can be broken into two parts, the decision on what is optimal today (i.e. what maximizes the *current return*) and the *optimal continuation path*. \n",
    "\n",
    "Along this path, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision ($x^*_{1}$). This is called the *Principle of Optimality*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Above we have stated the principle of optimality for the initial period. For a more general version, define the *set of feasible plans* as all plans that satisfy the constraints of the optimization problem when starting at an arbitrary state $x_t$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Phi(x_t) = \\big\\{ \\{x_s, y_s\\}_{s = t}^\\infty: y_s \\in G(x_s), \\ x_{s + 1} = F(x_s, y_s) \\quad \\text{for}\\ s = t, t+1, ... \\big\\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Moreover, make the following assumption:\n",
    "\n",
    "**Assumption**: $G(x)$ is non-empty for all $x \\in X$. Moreover, for all $x(0) \\in X$ and $\\{x_t, y_t\\}_{t = 0}^\\infty \\in \\Phi(x_0)$, $\\lim_{n \\rightarrow \\infty} \\sum^n_{t = 0} \\beta^t U(x_t, y_t)$ exists and is finite.\n",
    "\n",
    "In words, for any state, there is a feasible policy $y$. Moreover, in the limit, the discounted sum of per-period utilities does not converge to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We then have the following theorem.\n",
    "\n",
    "**Theorem (Principle of Optimality)**: Suppose the assumption above holds. Let $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty \\in \\Phi(x_0)$ be a feasible plan that attains $V^*(x_0)$ in the sequential problem above.  Then, \n",
    "\n",
    "\\begin{equation}\n",
    "   V^*(x^*_t) = U(x^*_t, y^*_t) + \\beta V^*\\big(F(x^*_{t}, y^*_t)\\big) \n",
    "\\end{equation}\n",
    "\n",
    "for $t = 0, 1, ...$, with $x^*_0 = x_0$. Moreover, if any $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty \\in \\Phi(x_0)$ satisfies this equation, then it attains the $V^*(x_0)$ in the sequential problem above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The principle of optimality essentially says two things:\n",
    "\n",
    "- The highest possible value that can be attained starting from $x^*_t$ can be split up in two parts: the optimal current return, which is a function of the current state and control $(x^*_{t}, y^*_t)$ and an continuation value that depends on the future state $F(x^*_{t}, y^*_t)$. This statement by itself is almost trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- The not-so-trivial part is that the continuation value is the highest possible value that can be attained starting from the state $F(x^*_{t}, y^*_t)$. While we are not going to strictly prove this, here is a heuristic argument. Suppose this were not the case and the continuation value were given by a function $\\tilde{V}$, with $\\tilde{V}\\big(F(x^*_{t}, y^*_t)\\big) < V^*\\big(F(x^*_{t}, y^*_t)\\big)$:\n",
    "\n",
    "\\begin{equation}\n",
    "   V^*(x^*_t) = U(x^*_t, y^*_t) + \\beta \\tilde{V}\\big(F(x^*_{t}, y^*_t)\\big) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the subsequent period, by assumption, value $V^*\\big(F(x^*_{t}, y^*_t)\\big)$ can attained by choosing $y_{t +1}^*$. However, a higher continuation value implies that a higher value can be attained in the current period, contradicting the assumption that the highest possible value is $V^*(x^*_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Equivalence of Values\n",
    "\n",
    "With respect to the Bellman equation being equivalent to the sequential problem, we need the following theorem.\n",
    "\n",
    "**Theorem (Equivalence of Values)**: Suppose the assumption above holds. Then for any $x \\in X$, any solution $V^*(x)$ to the sequential problem is also a solution to the Bellman equation\n",
    "\n",
    "\\begin{equation}\n",
    "    V(x)  =  \\max_{ y \\in G(x) }  U(x, y) + \\beta V\\big(F(x, y)\\big), \\quad \\forall x \\in X\n",
    "\\end{equation}\n",
    "\n",
    "Moreover, any solution $V(x)$ to the Bellman equation is also a solution to the sequential problem, so that $V^*(x) = V(x)$ for all $x \\in X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This theorem establishes that the value functions defined by the sequential and the recursive formulation of the problem are equivalent. \n",
    "\n",
    "However, we are ultimately interested in equivalence with respect to the solutions. Recall that by the principle of optimality, any feasible solution $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$ to the sequential problem satisfies \n",
    "\n",
    "\\begin{equation}\n",
    "   V^*(x^*_t) = U(x^*_t, y^*_t) + \\beta V^*\\big(F(x^*_{t}, y^*_t)\\big). \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Since we have just shown that $V^*(x) = V(x)$ for all $x \\in X$, we can write this as\n",
    "\n",
    "\\begin{equation}\n",
    "   V(x^*_t) = U(x^*_t, y^*_t) + \\beta V\\big(F(x^*_{t}, y^*_t)\\big). \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Moreover, consider a feasible sequence $\\{\\hat{x}_t, \\hat{y}_t\\}_{t = 0}^\\infty \\in \\Phi(x_0)$ that satisfies the Bellman equation *for a given value function* $V$. That is, for any period $t$, $\\hat{y}_t$ is the solution to the right hand side for the Bellman equation given the state $\\hat{x}_t$. Hence, for all $t = 0, 1, ...$, we have \n",
    "\n",
    "\\begin{equation}\n",
    "    V(\\hat{x}_t)  =  U(\\hat{x}_t, \\hat{y}_t) + \\beta V\\big(F(\\hat{x}_t, \\hat{y}_t)\\big).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Comparing the last two expressions, we see that $\\{x^*_t, y^*_t\\}_{t = 0}^\\infty$ satisfies the Bellman equation, and hence any solution to the sequential problem is also a solution to the recursive formulation of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
