{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Problem Set - Root Finding: Suggested Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2018-12-12 14:19:29.022465\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de), Christina Littlejohn (littlejohn@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (N)\n",
    "\n",
    "Write a function **mybisect(f, a, b)** in Python that implements the pseudo-code for the bisection method from the lecture. Then, test it on the function \n",
    "\\begin{equation*}\n",
    "    f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1,\n",
    "\\end{equation*}\n",
    "i.e. find a root of this function. Compare your result to what SciPy's in-built function returns. \n",
    "\n",
    "*Hint*: most modern programming languages have some type of **while**-loop, which will prove useful here. Moreover, in Python/NumPy, consider using the **abs()** and **np.sign()** functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use bisection on\n",
    "def fun(x):\n",
    "    return np.sin(4 * (x - 0.25)) + x + x**20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 29\n",
      "0.408293504267931\n",
      "0.4082935042806639\n"
     ]
    }
   ],
   "source": [
    "def mybisect(fun, a, b, maxit = 1000):\n",
    "    \"\"\"\n",
    "    Implements the bisection method\n",
    "    \"\"\"\n",
    "    ## check on signs of function values at initial points a and b\n",
    "    assert np.sign(fun(a)) == - np.sign(fun(b)), \"Choose a and b such that f(a) and f(b) have different signs\"\n",
    "    \n",
    "    # iteration counter\n",
    "    it = 0\n",
    "    # choose tolerance level\n",
    "    tol = 1e-10\n",
    "    # initialize d (= function value at x)\n",
    "    d = 1\n",
    "    # while-loop: iterate until d sufficiently small\n",
    "    while abs(d) > tol and it < maxit:\n",
    "        it += 1\n",
    "        # find intermediate value between a and b\n",
    "        x = (a + b)/2\n",
    "        # evaluate function\n",
    "        d = fun(x)\n",
    "        # find new end points for interval [a,b]\n",
    "        if np.sign(d) == np.sign(fun(a)):\n",
    "            a = x\n",
    "        elif np.sign(d) == np.sign(fun(b)):\n",
    "            b = x\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    return x\n",
    "\n",
    "print(mybisect(fun,0,2))        \n",
    "print(scipy.optimize.bisect(fun,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for different starting values -> will throw an error\n",
    "# print(mybisect(fun,-3,2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (N)\n",
    "\n",
    "Solve the example about the Cournot Duopoly in M&F, p. 35 ff., in Python using Newton's method, and compare your result to M&F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cournot(x):\n",
    "    \"\"\"\n",
    "    Implements a system of equations in two unknowns, here the Cournot Duopoly model\n",
    "    f_i(q1, q2) = [(q1 + q2)^(-1/eta) - (1/eta)*[(q1 + q2)^(-1/eta - 1)]*q_i - c_i*q_i]\n",
    "    \"\"\"\n",
    "    c = [0.6, 0.8]\n",
    "    eta = 1.6\n",
    "    e = -1/eta\n",
    "    \n",
    "    return np.array(( (x[0]+x[1])**e + e*((x[0]+x[1])**(e-1))*x[0] - c[0]*x[0],\n",
    "                    (x[0]+x[1])**e + e*((x[0]+x[1])**(e-1))*x[1] - c[1]*x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_J(x):\n",
    "    \"\"\"\n",
    "    Implements the Jacobian system of equation in two unknowns above\n",
    "    \"\"\"\n",
    "    c = [0.6, 0.8]\n",
    "    eta = 1.6\n",
    "    e = -1/eta\n",
    "    \n",
    "    f_00 = (e*(x[0]+x[1])**(e-2))*(e*x[0] + x[0] + 2*x[1]) - c[0] \n",
    "    f_01 = (e*(x[0]+x[1])**(e-2))*(e*x[0] + x[1])\n",
    "    f_10 = (e*(x[0]+x[1])**(e-2))*(e*x[1] + x[0])\n",
    "    f_11 = (e*(x[0]+x[1])**(e-2))*(e*x[1] + 2*x[0] + x[1]) - c[1]\n",
    "    \n",
    "    return np.array([[f_00, f_01], [f_10, f_11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_newton_mult(fun, fun_J, x,  tol = 1e-8, tol2 = 1e-6, maxit = 1000):\n",
    "    \"\"\"\n",
    "    Implements Newton's method for a vector-valued function\n",
    "    \"\"\"    \n",
    "    dist = 1\n",
    "    it = 0\n",
    "    while dist > tol and it < maxit:\n",
    "        it += 1\n",
    "        f, J = fun(x), fun_J(x)\n",
    "        x_new = x - np.linalg.inv(J) @ f\n",
    "        dist = np.linalg.norm(x - x_new) / (1 + np.linalg.norm(x))\n",
    "        x = x_new\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    if np.linalg.norm(fun(x)) < tol2: \n",
    "        return x\n",
    "    else:\n",
    "        print(\"No solution found!\")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 6\n",
      "[0.8395676  0.68879643]\n"
     ]
    }
   ],
   "source": [
    "x_init = [0.2, 0.2]\n",
    "x = my_newton_mult(cournot, fun_J, x_init)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (N)\n",
    "\n",
    "Modify the pseudo-code for Newton's method to include backstepping, as outlined in the lecture. Then, include backstepping to the Python function **my_newton**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-code for Newton's method with backstepping:\n",
    "\n",
    "(i) Specify tolerance levels $tol1$ and $tol2$ and choose a starting guess $x^{(0)}$.\n",
    "\n",
    "(ii) Compute the suggested step as \n",
    "\n",
    "\\begin{equation}\n",
    " s^{(k)} = - J(x^{(k)})^{-1} f(x^{(k)})\n",
    "\\end{equation}\n",
    "\n",
    "(iii) If $\\left| \\left|\\ f(x^{(k)} + s^{(k)}) \\right| \\right|$ < $\\left| \\left|\\ f(x^{(k)}) \\right| \\right|$, set $x^{(k+1)} = x^{(k)} + s^{(k)}$ and go to (vi).\n",
    "\n",
    "(iv) Otherwise, if $\\left| \\left|\\ f\\left(x^{(k)} + \\frac{s^{(k)}}{2}\\right) \\right| \\right|$ < $\\left| \\left|\\ f(x^{(k)} + s^{(k)}) \\right| \\right|$, set $s^{(k)} = \\frac{s^{(k)}}{2}$ and go back to (iii).\n",
    "\n",
    "(v) Otherwise, set $x^{(k+1)} = x^{(k)} + s^{(k)}$.\n",
    "\n",
    "(vi) Check the stopping rule: if $\\left| \\left|\\ x^{(k+1)} - x^{(k)}) \\right| \\right| < tol1$, stop. If not, go back to (ii).\n",
    "\n",
    "(vii) If $\\left| \\left|\\ f(x^{(k)}) \\right| \\right| < tol2$, report $x^{(k+1)}$ as the solution. Otherwise, report failure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_newton_bs(fun, fun_d, x,  tol1 = 1e-8,  tol2 = 1e-8, maxit = 100):\n",
    "    \"\"\"\n",
    "    Implements Newton's method for a vector-valued function with backstepping\n",
    "    \"\"\"    \n",
    "    dist = 1\n",
    "    it = 0\n",
    "    \n",
    "    while dist > tol1 and it < maxit:\n",
    "        it += 1\n",
    "        f, J = fun(x), fun_d(x)\n",
    "        ## step (ii): compute suggested step\n",
    "        s = - np.linalg.inv(J) @ f\n",
    "        \n",
    "        ## start backstepping routine\n",
    "        while np.linalg.norm( fun(x + s) ) > np.linalg.norm( fun(x) ): ## step (iii)\n",
    "            if np.linalg.norm( fun(x + 0.5 * s) ) < np.linalg.norm( fun(x + s) ): # step (iv)\n",
    "                s = 0.5 * s\n",
    "            else:   # step (v)\n",
    "                break ## terminate inner while loop \n",
    "        \n",
    "        x_new = x + s\n",
    "        dist = np.linalg.norm(x - x_new) / (1 + np.linalg.norm(x))\n",
    "        x = x_new\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    if np.linalg.norm( fun(x) ) < tol2:\n",
    "        return x\n",
    "    else:\n",
    "        print('No solution found!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the example from the lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 22\n",
      "[1.57079635 1.        ]\n"
     ]
    }
   ],
   "source": [
    "def fun_vv(x):\n",
    "    \"\"\"\n",
    "    Implements a system of equation in two unknowns, here f(x) = [x2**2 - 1; sin(x1) - x2]\n",
    "    \"\"\"\n",
    "    return np.array( (x[1]**2 - 1 , np.sin(x[0]) - x[1] ) )\n",
    "\n",
    "\n",
    "def fun_J(x):\n",
    "    \"\"\"\n",
    "    Implements the Jacobian system of equation in two unknowns above\n",
    "    \"\"\"\n",
    "    f_00 = 0\n",
    "    f_01 = 2 * x[1]\n",
    "    f_10 = np.cos(x[0])\n",
    "    f_11 = -1\n",
    "    \n",
    "    return np.array([[f_00, f_01], [f_10, f_11]])  \n",
    "\n",
    "        \n",
    "x_init = [1.5,0.9]\n",
    "x = my_newton_bs(fun_vv, fun_J, x_init)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write a function **mysecant(f, x0)** in Python that implements the pseudo-code for the secant method from the lecture. Again, test it on the function $f$ and compare the result to question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_secant(fun, f_old, x, x_old):\n",
    "    \"\"\"\n",
    "    Implements the update rule for the secant method\n",
    "    \"\"\"\n",
    "    f = fun(x)\n",
    "    fd = (f - f_old) / (x - x_old)\n",
    "\n",
    "    return x - f * fd**(-1), f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_secant(fun, x, tol1 = 1e-8,  tol2 = 1e-8, maxit = 100):\n",
    "    \"\"\"\n",
    "    Implements the secant method for a univariate scalar function\n",
    "    \"\"\"        \n",
    "    dist = 1\n",
    "    it = 0\n",
    "    \n",
    "    x_old = 0.9 * x\n",
    "    f_old = fun(x_old)\n",
    "\n",
    "    while dist > tol1 and it < maxit:\n",
    "        it += 1\n",
    "        x_new, f = g_secant(fun, f_old, x, x_old)\n",
    "        dist = abs(x - x_new) / (1 + abs(x))\n",
    "        \n",
    "        ## store \"old\" function and x value for next iteration\n",
    "        f_old = f\n",
    "        x_old = x\n",
    "        \n",
    "        x = x_new\n",
    "        print(x_new)\n",
    "\n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    if abs(fun(x)) < tol2: \n",
    "        return x\n",
    "    else:\n",
    "        print(\"No solution found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5603210327501603\n",
      "0.4399462903116683\n",
      "0.39893802965620273\n",
      "0.40864779800453077\n",
      "0.40829712124132966\n",
      "0.40829350284198784\n",
      "0.4082935042793729\n",
      "Number of iterations = 7\n",
      "693 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 my_secant(fun, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Scipy's **scipy.optimize.newton** (without providing a derivative) also applies the secant method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.408293504279372"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.newton(fun, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (N)\n",
    "\n",
    "Solve question 3.7 in M&F, p. 55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of agent $i$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max U_i(x) = \\sum_{j = 1}^2 a_{ij} (v_{ij} + 1)^{-1} x_{ij}^{v_{ij} + 1} \n",
    "\\end{equation}\n",
    "\n",
    "s.t. $p_1 x_{i1} + p_2 x_{i2} = p_1 e_{i1} + p_2 e_{i2}$. \n",
    "\n",
    "\n",
    "Taking first-conditions gives \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial U_i(x)}{\\partial x_{ij}} = U_{ij}(x) = a_{ij} x_{ij}^{v_{ij}} = \\lambda_i p_j\n",
    "\\end{equation},\n",
    "\n",
    "where $\\lambda_i$ is the Lagrange multiplier corresponding to agent $i$.\n",
    "\n",
    "Hence, we have three first order conditions, for $i \\in \\{1, 2, 3\\}$:\n",
    "\n",
    "\\begin{equation}\n",
    "     \\frac{ a_{i1} x_{i1}^{v_{i1}} }{p_1} - \\frac{ a_{i2} x_{i2}^{v_{i2}} }{p_2} = 0\n",
    "\\end{equation},\n",
    "\n",
    "Moreover, we have three budget constraints:\n",
    "\n",
    "\\begin{equation}\n",
    "    p_1 x_{i1} + p_2 x_{i2} - p_1 e_{i1} - p_2 e_{i2} = 0\n",
    "\\end{equation}\n",
    "\n",
    "Finally, the markets clear, implying two resource constraints:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum_{i} x_{i1} = \\sum_{i}  e_{i1},\\quad \\sum_{i} x_{i2} = \\sum_{i}  e_{i2}\n",
    "\\end{equation}\n",
    "\n",
    "In total, we have a system of 8 equations - three f.o.c.'s, three budget constraints and two resource constraints - in 7 variables, six quantities $x_{ij}$ and the price $p_1$ (recall that $p_2 = 1 - p_1$). Of course Walras' law applies: in the context of this question, given that the agents' budget constraints all hold with equality, if we have an equilibrium on one market (i.e. no excess demand or supply), we also have an equilibrium on the other market (make sure you are able to verify this!).\n",
    "\n",
    "Hence, we have to use only 7 of the 8 equations, without changing the problem. Note that applying Walras' law here is actually necessary from a purely computational point of view: recall that (Quasi-)Newton methods are based on solving a *square* system of linear equations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read parameters\n",
    "A = np.array([ [2.0, 1.5],\n",
    "               [1.5, 2.0],\n",
    "               [1.5, 2.0]  ])\n",
    "\n",
    "V = np.array([ [-2.0, -0.5],\n",
    "               [-1.5, -0.5],\n",
    "               [-0.5, -1.5] ])\n",
    "\n",
    "E = np.array([ [2.0, 3.0],\n",
    "               [1.0, 2.0],\n",
    "               [4.0, 0.0]  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define residual function\n",
    "\n",
    "def S(z, A, V, E):\n",
    "    \n",
    "    X = np.array([ [np.exp(z[0]), np.exp(z[1])],\n",
    "               [np.exp(z[2]), np.exp(z[3])],\n",
    "               [np.exp(z[4]), np.exp( z[5])]  ])\n",
    "    p1 = np.exp( z[6])\n",
    "    \n",
    "    S = np.zeros(7)\n",
    "    \n",
    "    ### f.o.c.'s\n",
    "    for i in range(3):\n",
    "        S[i] = A[i, 0] * X[i, 0]**V[i, 0] / p1 - A[i, 1] * X[i, 1]**V[i, 1] / (1 - p1)\n",
    "    \n",
    "    ## budget constraints\n",
    "    for i in range(3):\n",
    "        S[3 + i] = p1 * X[i, 0] + (1 - p1) * X[i, 1] - (p1 * E[i, 0] + (1 - p1) * E[i, 1])\n",
    "    \n",
    "    \n",
    "    ## resource constraint good 1 and 2\n",
    "    S[6] = np.sum(X[:, 0], axis = 0) - np.sum(E[:, 0], axis = 0)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: array([-7.16270507e-08,  1.24932218e-07,  2.75794282e-06, -1.06633794e-07,\n",
      "       -4.26687452e-07,  8.80209219e-08, -1.98529451e-06])\n",
      " message: 'A solution was found at the specified tolerance.'\n",
      "     nit: 32\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([ 1.06485824,  1.01624014,  0.86227772,  0.4943689 ,  0.54871128,\n",
      "       -0.51458403, -1.56775563])\n",
      "[2.90042778 2.76278752 2.36854945 1.63946325 1.73102078 0.59774919\n",
      " 0.20851264]\n"
     ]
    }
   ],
   "source": [
    "## initial guess - recall that variables are in logs!\n",
    "z0 = np.array([1, 1, 0.5, 0.5, 0.5, 0.5, -1])\n",
    "## solve the problem\n",
    "res = scipy.optimize.root(S, z0, method = 'broyden1', args = (A, V, E))\n",
    "print(res)\n",
    "print( np.exp( res.x ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note the approach above is just one of several possible. In particular, we reduce the dimension of the solution vector by substituting the budget and resource constraints (rather than using them as functions in our system). In the extreme case, you can reduce the system to three equations in three unknown variables ($x_{11}, x_{21}, p1$).\n",
    "\n",
    "However, while this is fine conceptually, it is not recommended from a numerical perspective. In particular, we run the risk sure that the variables computed inside the function (rather than solved for directly) are negative. Hence, reducing the dimension of the solution vector does not reduce coding time, and can be quite unstable numerically.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define alternative residual function (with three arguments)\n",
    "\n",
    "def S_alt(z, A, V, E):\n",
    "    \n",
    "    x11 = np.exp(z[0])\n",
    "    x21 = np.exp(z[1])\n",
    "    p1 = np.exp(z[2])\n",
    "\n",
    "    S = np.zeros(3)\n",
    "    \n",
    "    ## derived variables\n",
    "    ## use budget constraints for to get remaining quantities for consumers 1 and 2\n",
    "    x12 = (-p1 * x11 + (p1 * E[0, 0] + (1 - p1) * E[0, 1]) ) / (1 - p1) \n",
    "    x22 = (-p1 * x21 + (p1 * E[1, 0] + (1 - p1) * E[1, 1]) ) / (1 - p1) \n",
    "\n",
    "    ## use resource constraints to get quantities for consumer 3\n",
    "    x31 = np.sum(E[:, 0], axis = 0) - x11 - x21\n",
    "    x32 = np.sum(E[:, 1], axis = 0) - x12 - x22\n",
    "\n",
    "    ### f.o.c.'s\n",
    "\n",
    "    S[0] = A[0, 0] * x11**V[0, 0] / p1 - A[0, 1] * x12**V[0, 1] / (1 - p1)\n",
    "    S[1] = A[1, 0] * x21**V[1, 0] / p1 - A[1, 1] * x22**V[1, 1] / (1 - p1)\n",
    "    S[2] = A[2, 0] * x31**V[2, 0] / p1 - A[2, 1] * x32**V[2, 1] / (1 - p1)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.73597544e-08,  4.05430368e-07, -9.05020796e-06])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initial guess - use corresponding values found above and recall that variables are in logs!\n",
    "z0_alt = np.array([np.log(2.90042778), np.log(2.36854945), np.log(0.20851264)])\n",
    "S_alt(z0_alt, A, V, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## solve the problem -> NOTE THAT WE DON'T GET CONVERGENCE HERE, EVEN WHEN STARTING AT THE RIGHT VALUES!\n",
    "# res = scipy.optimize.root(S_alt, z0_alt, method = 'broyden2', args = (A, V, E))\n",
    "# print(res)\n",
    "# print( np.exp( res.x ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (A)\n",
    "\n",
    "(a) Show that the update rule for $A^{(k+1)}$ used in Broyden's method,\n",
    "\n",
    "\\begin{equation}\n",
    " A^{(k+1)} = A^{(k)} + \\frac{ \\left( \\mathbf{f}(\\mathbf{x}^{(k+1)}) - \\mathbf{f}(\\mathbf{x}^{(k)}) - A^{(k)} \\mathbf{p}^{(k)} \\right) (\\mathbf{p}^{(k)})^T}{(\\mathbf{p}^{(k)})^T \\mathbf{p}^{(k)}}\n",
    "\\end{equation}\n",
    "\n",
    "satisfies the secant condition,\n",
    "\n",
    "\\begin{equation}\n",
    " A^{(k+1)} \\mathbf{p}^{(k)} = \\mathbf{f}(\\mathbf{x}^{(k+1)}) - \\mathbf{f}(\\mathbf{x}^{(k)}).\n",
    "\\end{equation}\n",
    "\n",
    " and\n",
    "\n",
    "\\begin{equation}\n",
    " A^{(k+1)} \\mathbf{q} = A^{(k)} \\mathbf{q}\\ \\ \\text{for}\\ \\ \\mathbf{q}^{T} \\mathbf{p}^{(k)} = 0\n",
    "\\end{equation}.\n",
    "\n",
    "(b) To prepare question (c), Show that for any vector $\\mathbf{p} \\in \\mathbb{R}^n$, we have \n",
    "\n",
    "\\begin{equation}\n",
    "    \\left| \\left| \\frac{\\mathbf{p}\\ \\mathbf{p}^T}{\\mathbf{p}^T \\mathbf{p} } \\right| \\right| = 1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "(c) Using the result from question (b), show that\n",
    "\n",
    "\\begin{equation}\n",
    " A^{(k+1)} \\in \\arg \\min_{A :\\ A \\mathbf{p}^{(k)} = \\mathbf{f}(\\mathbf{x}^{(k+1)}) - \\mathbf{f}(\\mathbf{x}^{(k)})} ||\\ A - A^{(k)} ||\n",
    "\\end{equation}\n",
    "\n",
    "Hint: Use the update rule in (a) to rewrite the distance $||\\ A^{(k+1)}  - A^{(k)} ||$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
